{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random proxy taken from https://codelike.pro/create-a-crawler-with-rotating-ip-proxy-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import random\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.basketball-reference.com/boxscores/?month=01&day=18&year=2019',\n",
    "        'https://www.basketball-reference.com/boxscores/?month=01&day=19&year=2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_url = 'https://www.basketball-reference.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluff_number(x, digits = 2):\n",
    "    y = str(x)\n",
    "    gap = digits - len(str(x))\n",
    "    if gap > 0:\n",
    "        for i in range(gap):\n",
    "            y = '0' + y\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_proxy(proxies):\n",
    "    return random.randint(0, len(proxies) - 1)\n",
    "\n",
    "def open_with_proxy(u, max_tries = 20):\n",
    "    ua = UserAgent() # From here we generate a random user agent\n",
    "    proxies = [] # Will contain proxies [ip, port]\n",
    "\n",
    "    # Retrieve latest proxies\n",
    "    proxies_req = Request('https://www.sslproxies.org/')\n",
    "    proxies_req.add_header('User-Agent', ua.random)\n",
    "    proxies_doc = urlopen(proxies_req).read().decode('utf8')\n",
    "\n",
    "    soup = BeautifulSoup(proxies_doc, 'html.parser')\n",
    "    proxies_table = soup.find(id='proxylisttable')\n",
    "\n",
    "  # Save proxies in the array\n",
    "    for row in proxies_table.tbody.find_all('tr'):\n",
    "        proxies.append({\n",
    "            'ip':   row.find_all('td')[0].string,\n",
    "            'port': row.find_all('td')[1].string \n",
    "      })\n",
    "\n",
    "    connected = False\n",
    "    num_tries = 0\n",
    "\n",
    "    while connected is False:\n",
    "        # Generate a random proxy\n",
    "        proxy_index = random_proxy(proxies)\n",
    "        proxy = proxies[proxy_index]\n",
    "        num_tries += 1\n",
    "    \n",
    "        req = Request(u)\n",
    "        req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "\n",
    "        try:\n",
    "            html = urlopen(req).read().decode('utf8')\n",
    "            connected = True\n",
    "            print('Connected with ' + str(num_tries) + ' tries')\n",
    "            return(html)\n",
    "        except: # If error, delete this proxy and find another one\n",
    "            del proxies[proxy_index]\n",
    "            if num_tries > 20:\n",
    "                print('Unable to connect. Max tries reached')\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_games_from_date(month, day, year):\n",
    "    site_url = 'http://www.basketball-reference.com'\n",
    "    u = 'http://www.basketball-reference.com/boxscores/?'\n",
    "    u += 'month=' + fluff_number(month)\n",
    "    u += '&day=' + fluff_number(day)\n",
    "    u += '&year=' + str(year)\n",
    "    print(u)\n",
    "    #req = Request(u)\n",
    "    #req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "    #html = urlopen(req)\n",
    "    html = open_with_proxy(u)\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = [site_url + x['href'] for x in soup.find_all('a', text = 'Box Score')]\n",
    "    return(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_from_tr(tr):\n",
    "    return([tr.find('th')['csk'], dict([(x['data-stat'], x.text) for x in tr.find_all('td')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_from_game(u):\n",
    "    game_name = u.split('/')[-1].split('.')[0]\n",
    "    #proxy_index = random_proxy()\n",
    "    #proxy = proxies[proxy_index]\n",
    "\n",
    "    #req = Request(u)\n",
    "    #req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "\n",
    "    #html = urlopen(req)\n",
    "    time_to_sleep = random.randint(1,10)\n",
    "    time.sleep(time_to_sleep)\n",
    "    html = open_with_proxy(u)\n",
    "    soup = BeautifulSoup(html)\n",
    "    tables = soup.find_all('table', attrs={'class': 'stats_table'})\n",
    "    table_tuples = [(tbl['id'].split('_')[1], [tr for tr in tbl.find_all('tr') if tr.find('th').has_attr('csk')]) for tbl in tables]\n",
    "    # Get all of the rows whose first header contains the csk attribute\n",
    "    # trs = [tr for tr in soup.find_all('tr') if tr.find('th').has_attr('csk')]\n",
    "    data = [(tbl_tup[0], [get_stat_from_tr(tr) for tr in tbl_tup[1]]) for tbl_tup in table_tuples]\n",
    "\n",
    "    d = {}\n",
    "    for tbl in data:\n",
    "        team = tbl[0]\n",
    "        for player in tbl[1]:\n",
    "            player_name = player[0]\n",
    "            d[player_name] = {**{'team': team, 'game': game_name}, **player[1]}\n",
    "    df = pd.DataFrame(d).T\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_date(month, day, year):\n",
    "    data = pd.concat([get_table_from_game(game) for game in get_games_from_date(month, day, year)])\n",
    "    data['year'] = year\n",
    "    data['month'] = month\n",
    "    data['day'] = day\n",
    "    data['date'] = str(year) + '-' + fluff_number(month) + '-' + fluff_number(day)\n",
    "    data['player'] = data.index\n",
    "    # data = data.set_index(['game', 'player'])\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_connection():\n",
    "    import sqlalchemy\n",
    "    database_username = 'bchnge'\n",
    "    database_password = 'letmeintomysql123'\n",
    "    database_ip       = '207.38.183.229:6603'\n",
    "    database_name     = 'db_nba'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                                   format(database_username, database_password, \n",
    "                                                          database_ip, database_name))\n",
    "    return(database_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_db(con, df):\n",
    "    df.to_sql(con=con, name='games_players', if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = get_sql_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(con, month, day, year):\n",
    "    try:\n",
    "        games_data = get_data_from_date(month, day, year)\n",
    "        save_to_db(con, games_data)\n",
    "        print('hooray')\n",
    "    except:\n",
    "        print('no games. moving on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "numdays = 365 * 5\n",
    "base = datetime.datetime.today()\n",
    "date_list = [base - datetime.timedelta(days=x) for x in range(0, numdays)]\n",
    "dates = [(x.month, x.day, x.year) for x in date_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.basketball-reference.com/boxscores/?month=01&day=21&year=2019\n",
      "Connected with 1 tries\n",
      "no games. moving on\n",
      "http://www.basketball-reference.com/boxscores/?month=01&day=20&year=2019\n",
      "Connected with 1 tries\n",
      "Connected with 1 tries\n",
      "Connected with 1 tries\n",
      "Connected with 1 tries\n",
      "hooray\n",
      "http://www.basketball-reference.com/boxscores/?month=01&day=19&year=2019\n",
      "Connected with 1 tries\n",
      "Connected with 2 tries\n",
      "Connected with 1 tries\n",
      "Connected with 1 tries\n",
      "Connected with 3 tries\n",
      "Connected with 2 tries\n",
      "Connected with 1 tries\n",
      "Connected with 1 tries\n",
      "Connected with 1 tries\n"
     ]
    }
   ],
   "source": [
    "for x in dates:\n",
    "    download_data(con, x[0], x[1], x[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
